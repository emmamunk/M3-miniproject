---
title: "M3-project"
date: "24 nov 2019"
output:
  html_document:
    code_folding: hide
    df_print: paged
    number_sections: yes
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---
# Introduction

# Problem

# Data desciption

# Data preprocessing 

## Load libaries

We start by cleaning the environment.

```{r, include=FALSE}
#Cleaning the environment
rm(list=ls())
```

And then we'll import Keras, which is essential for the anaysis. You have to use "install_keras" if you're installing Keras for the first time.

```{r}
#devtools::install_github("rstudio/keras", force = TRUE)
#library(keras)
#install_keras()
```

And then we'll load a bunch of other packages.

```{r}
#Loading packages
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr,
               readr,
               rmarkdown, 
               tidyverse,
               dplyr,
               broom,
               keras,
               drat,
               reticulate,
               SciencesPo,
               caret,
               textstem
               )
```

## Data

And now we can download the data from the Github.

```{r}
listings <- read_csv("C:/Users/Michael Thomsen/Desktop/Stockholm/listings.csv")
reviews <- read_csv("C:/Users/Michael Thomsen/Desktop/Stockholm/reviews_detailed.csv")

```

```{r}
listings = read_csv("C:/Users/Emma/OneDrive/Universitetet/stockholm-sweden-airbnb-listings/listings_detailed.csv")

reviews = read_csv("C:/Users/Emma/OneDrive/Universitetet/stockholm-sweden-airbnb-listings/reviews_detailed.csv")
```

## Data preprocessing

In the variable listings, there's a lof of variables. We have choosen some of them, including id, neighbourhood, room type, minimum nights, number of reviews, reviews per month, calculated host listings count and availability 365.

```{r}
listings = listings %>% select(c(price, id, neighbourhood, room_type, minimum_nights, number_of_reviews, reviews_per_month, calculated_host_listings_count, availability_365)) %>% as_tibble()
```

And then we'll remove NA's.

```{r}
listings = na.omit(listings)
```

After removing NA's, we're down to 6273 observationsa and eight variables. Now, we'll remove every listing, where availability is equal to zero. 

```{r}
listings = listings %>% filter(availability_365 > 0)
```

## Understanding the data
Now we're going to get a understanding of the variables. The first one is neighbourhoods.

```{r}
table(listings$neighbourhood)
```

Here we can see that there's 14 different neighbourhoods. The next variable is room type.

```{r}
table(listings$room_type)
```

Here, we can see that most of the rooms are either entire hooms/apartments or a private room. NOw, let's look at the mininum nights.

```{r}
table(listings$minimum_nights)
```

Here, we can see that the number of observation slowly decreses as number og minimum nights increses. The mininum is 1 and the maximum is 500. Here we could do some filtering, but we're not going to do that as there's a few of the apartments where the minimum nights is quiet high, but we're not going to filter for it.  

```{r}
summary(listings$number_of_reviews)
```

Here, we run a summary. The minimum number of reviews is 1 while the maximum number of reviews is 508. Here the mean number of reviews is 28.59, while the median is 12 

```{r}
summary(listings$reviews_per_month)
```

Here, we run a summary again. The minium reviews per months id 0.02 while the maxium is 10.49. The median is 1.61 and the mean is 1.00. 

```{r}
summary(listings$calculated_host_listings_count)
```

Here the calculated host listings count goes from 1, which is the minimum, to 116, which is the maximum. Most have 1, as median is 1. Mean is 2.22. And lastely, availability.

```{r}
summary(listings$availability_365)
```

Here the minimum is 1 and the maximum is 365. The median is 93 and the mean is 141.

```{r}
listings$price = as.numeric(gsub('[$,]', '', listings$price))
```


# Supervised machine learning

We'll start by splitting the data into test and training.

```{r}
index = createDataPartition(y = listings$price, p = 0.75, list = FALSE)

training = listings[index,] 
test = listings[-index,] 
```

```{r}
fit_lm = lm(price ~ ., data = listings)
fit_lm %>% summary()
```

```{r}
reci <- recipe(medv ~ ., data = training) %>%
  step_center(all_numeric(), -all_outcomes()) %>% # Centers all numeric variables to mean = 0
  step_scale(all_numeric(), -all_outcomes()) %>% # scales all numeric variables to sd = 1
  step_zv(all_predictors())  # Removed predictors with zero variance


# knn inputation of missing values
reci %<>%
  step_knnimpute(all_predictors()) 

# Recipe in the end has to be prepared on the treining data
reci %<>% 
  prep(data = train)
```













































############################STOP HER EMMA!!!!!!!!!!!!!!!!!!!!!!####################################
Data preprocessing NLP
```{r}

```

